{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  mne\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from numpy import ndarray\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.sparse import block_diag, identity, vstack, spmatrix\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import eigh, pinv, qr\n",
    "from typing import Optional, List, cast\n",
    "from functools import partial\n",
    "from scipy.signal import filtfilt, cheb1ord, cheby1\n",
    "import scipy.linalg as linalg\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "from pyriemann.estimation import Covariances\n",
    "import pickle\n",
    "from brainflow import BoardShim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_data(X):\n",
    "    \"\"\"Check data is numpy array and has the proper dimensions.\"\"\"\n",
    "    if not isinstance(X, (np.ndarray, list)):\n",
    "        raise AttributeError('data should be a list or a numpy array')\n",
    "\n",
    "    dtype = np.complex128 if np.any(np.iscomplex(X)) else np.float64\n",
    "    X = np.asanyarray(X, dtype=dtype)\n",
    "    if X.ndim > 3:\n",
    "        raise ValueError('Data must be 3D at most')\n",
    "\n",
    "    return X\n",
    "\n",
    "def theshapeof(X):\n",
    "    \"\"\"Return the shape of X.\"\"\"\n",
    "    X = _check_data(X)\n",
    "    # if not isinstance(X, np.ndarray):\n",
    "    #     raise AttributeError('X must be a numpy array')\n",
    "\n",
    "    if X.ndim == 3:\n",
    "        return X.shape[0], X.shape[1], X.shape[2]\n",
    "    elif X.ndim == 2:\n",
    "        return X.shape[0], X.shape[1], 1\n",
    "    elif X.ndim == 1:\n",
    "        return X.shape[0], 1, 1\n",
    "    else:\n",
    "        raise ValueError(\"Array contains more than 3 dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass(eeg, sfreq, Wp, Ws):\n",
    "    \"\"\"Filter bank design for decomposing EEG data into sub-band components.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eeg : np.array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "    sfreq : int\n",
    "        Sampling frequency of the data.\n",
    "    Wp : 2-tuple\n",
    "        Passband for Chebyshev filter.\n",
    "    Ws : 2-tuple\n",
    "        Stopband for Chebyshev filter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y: np.array, shape=(n_trials, n_chans, n_samples)\n",
    "        Sub-band components decomposed by a filter bank.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    scipy.signal.cheb1ord :\n",
    "        Chebyshev type I filter order selection.\n",
    "\n",
    "    \"\"\"\n",
    "    # Chebyshev type I filter order selection.\n",
    "    N, Wn = cheb1ord(Wp, Ws, 3, 40, fs=sfreq)\n",
    "\n",
    "    # Chebyshev type I filter design\n",
    "    B, A = cheby1(N, 0.5, Wn, btype=\"bandpass\", fs=sfreq)\n",
    "\n",
    "    # the arguments 'axis=0, padtype='odd', padlen=3*(max(len(B),len(A))-1)'\n",
    "    # correspond to Matlab filtfilt : https://dsp.stackexchange.com/a/47945\n",
    "    y = filtfilt(B, A, eeg, axis=0, padtype='odd',\n",
    "                 padlen=3 * (max(len(B), len(A)) - 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "def schaefer_strimmer_cov(X):\n",
    "    r\"\"\"Schaefer-Strimmer covariance estimator.\n",
    "\n",
    "    Shrinkage estimator described in [1]_:\n",
    "\n",
    "    .. math:: \\hat{\\Sigma} = (1 - \\gamma)\\Sigma_{scm} + \\gamma T\n",
    "\n",
    "    where :math:`T` is the diagonal target matrix:\n",
    "\n",
    "    .. math:: T_{i,j} = \\{ \\Sigma_{scm}^{ii} \\text{if} i = j,\n",
    "         0 \\text{otherwise} \\}\n",
    "\n",
    "    Note that the optimal :math:`\\gamma` is estimated by the authors' method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array, shape=(n_chans, n_samples)\n",
    "        Signal matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cov: array, shape=(n_chans, n_chans)\n",
    "        Schaefer-Strimmer shrinkage covariance matrix.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Schafer, J., and K. Strimmer. 2005. A shrinkage approach to\n",
    "       large-scale covariance estimation and implications for functional\n",
    "       genomics. Statist. Appl. Genet. Mol. Biol. 4:32.\n",
    "    \"\"\"\n",
    "    ns = X.shape[1]\n",
    "    C_scm = np.cov(X, ddof=0)\n",
    "    X_c = X - np.tile(X.mean(axis=1), [ns, 1]).T\n",
    "\n",
    "    # Compute optimal gamma, the weigthing between SCM and srinkage estimator\n",
    "    R = ns / (ns - 1.0) * np.corrcoef(X)\n",
    "    var_R = (X_c ** 2).dot((X_c ** 2).T) - 2 * C_scm * X_c.dot(X_c.T)\n",
    "    var_R += ns * C_scm ** 2\n",
    "\n",
    "    var_R = ns / ((ns - 1) ** 3 * np.outer(X.var(1), X.var(1))) * var_R\n",
    "    R -= np.diag(np.diag(R))\n",
    "    var_R -= np.diag(np.diag(var_R))\n",
    "    gamma = max(0, min(1, var_R.sum() / (R ** 2).sum()))\n",
    "\n",
    "    cov = (1. - gamma) * (ns / (ns - 1.)) * C_scm\n",
    "    cov += gamma * (ns / (ns - 1.)) * np.diag(np.diag(C_scm))\n",
    "\n",
    "    return cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trca(X):\n",
    "    \"\"\"Task-related component analysis.\n",
    "\n",
    "    This function implements the method described in [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    W : array, shape=(n_chans,)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Covariance\n",
    "    Q = UX @ UX.T\n",
    "\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    S = np.zeros((n_chans, n_chans))\n",
    "    for trial_i in range(n_trials - 1):\n",
    "        x1 = np.squeeze(X[..., trial_i])\n",
    "\n",
    "        # Mean centering for the selected trial\n",
    "        x1 -= np.mean(x1, 0)\n",
    "\n",
    "        # Select a second trial that is different\n",
    "        for trial_j in range(trial_i + 1, n_trials):\n",
    "            x2 = np.squeeze(X[..., trial_j])\n",
    "\n",
    "            # Mean centering for the selected trial\n",
    "            x2 -= np.mean(x2, 0)\n",
    "\n",
    "            # Compute empirical covariance between the two selected trials and\n",
    "            # sum it\n",
    "            S = S + x1.T @ x2 + x2.T @ x1\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best\n",
    "\n",
    "\n",
    "def trca_regul(X, method):\n",
    "    \"\"\"Task-related component analysis.\n",
    "\n",
    "    This function implements a variation of the method described in [1]_. It is\n",
    "    inspired by a riemannian geometry approach to CSP [2]_. It adds\n",
    "    regularization to the covariance matrices and uses the riemannian mean for\n",
    "    the inter-trial covariance matrix `S`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    W : array, shape=(n_chans,)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
    "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
    "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
    "       472-476). IEEE.\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Compute empirical variance of all data (to be bounded)\n",
    "    cov = Covariances(estimator=method).fit_transform(UX[np.newaxis, ...])\n",
    "    Q = np.squeeze(cov)\n",
    "\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Intertrial correlation computation\n",
    "    data = np.concatenate((X, X), axis=1)\n",
    "\n",
    "    # Swapaxes to fit pyriemann Covariances\n",
    "    data = np.swapaxes(data, 0, 2)\n",
    "    cov = Covariances(estimator=method).fit_transform(data)\n",
    "\n",
    "    # Keep only inter-trial\n",
    "    S = cov[:, :n_chans, n_chans:] + cov[:, n_chans:, :n_chans]\n",
    "\n",
    "    # If the number of samples is too big, we compute an approximate of\n",
    "    # riemannian mean to speed up the computation\n",
    "    if n_trials < 30:\n",
    "        S = mean_covariance(S, metric='riemann')\n",
    "    else:\n",
    "        S = mean_covariance(S, metric='logeuclid')\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best\n",
    "\n",
    "\n",
    "\n",
    "def get_corr(a,b, latency=20):\n",
    "    cross_correlation = abs(np.correlate(a,b, mode='same'))\n",
    "    center_idx = len(cross_correlation) // 2\n",
    "    max_corr = cross_correlation[center_idx-latency  : center_idx+latency].max()\n",
    "    return max_corr\n",
    "\n",
    "def trca_crosscorrelation(X):\n",
    "    latency=250\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Covariance\n",
    "    # Q = UX @ UX.T\n",
    "    # Use my cross correlation\n",
    "    Q = np.zeros((UX.shape[0],UX.shape[0]))\n",
    "    for i in range(UX.shape[0]):\n",
    "        for j in range(UX.shape[0]):\n",
    "            a = UX[i]\n",
    "            b = UX[j]\n",
    "            Q[i,j] = get_corr(a,b,latency=latency)\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    S = np.zeros((n_chans, n_chans))\n",
    "    for i in range(n_chans):\n",
    "        for j in range(n_chans):\n",
    "            # n_samples, n_chans, n_trials \n",
    "            x_i = X[:, i, :]\n",
    "            x_j = X[:, j, :]\n",
    "            # print(f\"{x_i.shape=}\")\n",
    "            # print(f\"{x_j.shape=}\")\n",
    "            for t1 in range(n_trials):\n",
    "                for t2 in range(n_trials):\n",
    "                    if(t1 == t2): continue\n",
    "                    x_i_t1 = np.squeeze(x_i[:,t1])\n",
    "                    x_i_t1 -= x_i_t1.mean()\n",
    "\n",
    "                    x_j_t2 = np.squeeze(x_j[:,t2])\n",
    "                    x_j_t2 -= x_j_t2.mean()\n",
    "                    \n",
    "                    S[i,j] += get_corr(x_i_t1, x_j_t2, latency=latency)\n",
    "    # for trial_i in range(n_trials - 1):\n",
    "    #     x1 = np.squeeze(X[..., trial_i])\n",
    "\n",
    "    #     # Mean centering for the selected trial\n",
    "    #     x1 -= np.mean(x1, 0)\n",
    "\n",
    "    #     # Select a second trial that is different\n",
    "    #     for trial_j in range(trial_i + 1, n_trials):\n",
    "    #         x2 = np.squeeze(X[..., trial_j])\n",
    "\n",
    "    #         # Mean centering for the selected trial\n",
    "    #         x2 -= np.mean(x2, 0)\n",
    "\n",
    "    #         # Compute empirical covariance between the two selected trials and\n",
    "    #         # sum it\n",
    "    #         S = S + x1.T @ x2 + x2.T @ x1\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRCA:\n",
    "    \"\"\"Task-Related Component Analysis (TRCA).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sfreq : float\n",
    "        Sampling rate.\n",
    "    filterbank : list[[2-tuple, 2-tuple]]\n",
    "        Filterbank frequencies. Each list element is itself a list of passband\n",
    "        `Wp` and stopband `Ws` edges frequencies `[Wp, Ws]`. For example, this\n",
    "        creates 3 bands, starting at 6, 14, and 22 hz respectively::\n",
    "\n",
    "            [[(6, 90), (4, 100)],\n",
    "             [(14, 90), (10, 100)],\n",
    "             [(22, 90), (16, 100)]]\n",
    "\n",
    "        See :func:`scipy.signal.cheb1ord()` for more information on how to\n",
    "        specify the `Wp` and `Ws`.\n",
    "    ensemble : bool\n",
    "        If True, perform the ensemble TRCA analysis (default=False).\n",
    "    method : str in {'original'| 'riemann'}\n",
    "        Use original implementation from [1]_ or a variation that uses\n",
    "        regularization and the geodesic mean [2]_.\n",
    "    regularization : str in {'schaefer' | 'lwf' | 'oas' | 'scm'}\n",
    "        Regularization estimator used for covariance estimation with the\n",
    "        `riemann` method. Consider 'schaefer', 'lwf', 'oas'. 'scm' does not add\n",
    "        regularization and is almost equivalent to the original implementation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    traindata : array, shape=(n_bands, n_chans, n_trials)\n",
    "        Reference (training) data decomposed into sub-band components by the\n",
    "        filter bank analysis.\n",
    "    y_train : array, shape=(n_trials)\n",
    "        Labels associated with the train data.\n",
    "    coef_ : array, shape=(n_chans, n_chans)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "    classes : list\n",
    "        Classes.\n",
    "    n_bands : int\n",
    "        Number of sub-bands.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
    "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
    "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
    "       472-476). IEEE.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sfreq, filterbank, ensemble=False, method='original',\n",
    "                 estimator='scm'):\n",
    "        self.sfreq = sfreq\n",
    "        self.ensemble = ensemble\n",
    "        self.filterbank = filterbank\n",
    "        self.n_bands = len(self.filterbank)\n",
    "        self.coef_ = None\n",
    "        self.method = method\n",
    "        if estimator == 'schaefer':\n",
    "            self.estimator = schaefer_strimmer_cov\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Training stage of the TRCA-based SSVEP detection.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "            Training EEG data.\n",
    "        y : array, shape=(trials,)\n",
    "            True label corresponding to each trial of the data array.\n",
    "\n",
    "        \"\"\"\n",
    "        n_samples, n_chans, _ = theshapeof(X)\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        trains = np.zeros((len(classes), self.n_bands, n_samples, n_chans))\n",
    "\n",
    "        W = np.zeros((self.n_bands, len(classes), n_chans))\n",
    "\n",
    "        for class_i in classes:\n",
    "            # Select data with a specific label\n",
    "            eeg_tmp = X[..., y == class_i]\n",
    "            for fb_i in range(self.n_bands):\n",
    "                # Filter the signal with fb_i\n",
    "                eeg_tmp = bandpass(eeg_tmp, self.sfreq,\n",
    "                                   Wp=self.filterbank[fb_i][0],\n",
    "                                   Ws=self.filterbank[fb_i][1])\n",
    "                if (eeg_tmp.ndim == 3):\n",
    "                    # Compute mean of the signal across trials\n",
    "                    trains[class_i, fb_i] = np.mean(eeg_tmp, -1)\n",
    "                else:\n",
    "                    trains[class_i, fb_i] = eeg_tmp\n",
    "                # Find the spatial filter for the corresponding filtered signal\n",
    "                # and label\n",
    "                if self.method == 'original':\n",
    "                    w_best = _trca(eeg_tmp)\n",
    "                elif self.method == 'riemann':\n",
    "                    w_best = trca_regul(eeg_tmp, self.estimator)\n",
    "                elif self.method == 'crosscorrelation':\n",
    "                    w_best = trca_crosscorrelation(eeg_tmp)\n",
    "                else:\n",
    "                    raise ValueError('Invalid `method` option.')\n",
    "\n",
    "                W[fb_i, class_i, :] = w_best  # Store the spatial filter\n",
    "\n",
    "        self.trains = trains\n",
    "        self.coef_ = W\n",
    "        self.classes = classes\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Test phase of the TRCA-based SSVEP detection.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array, shape=(n_samples, n_chans[, n_trials])\n",
    "            Test data.\n",
    "        model: dict\n",
    "            Fitted model to be used in testing phase.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred: np.array, shape (trials)\n",
    "            The target estimated by the method.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.coef_ is None:\n",
    "            raise RuntimeError('TRCA is not fitted')\n",
    "\n",
    "        # Alpha coefficients for the fusion of filterbank analysis\n",
    "        fb_coefs = [(x + 1)**(-1.25) + 0.25 for x in range(self.n_bands)]\n",
    "        _, _, n_trials = theshapeof(X)\n",
    "\n",
    "        r = np.zeros((self.n_bands, len(self.classes)))\n",
    "        pred = np.zeros((n_trials), 'int')  # To store predictions\n",
    "\n",
    "        for trial in range(n_trials):\n",
    "            test_tmp = X[..., trial]  # pick a trial to be analysed\n",
    "            for fb_i in range(self.n_bands):\n",
    "\n",
    "                # filterbank on testdata\n",
    "                testdata = bandpass(test_tmp, self.sfreq,\n",
    "                                    Wp=self.filterbank[fb_i][0],\n",
    "                                    Ws=self.filterbank[fb_i][1])\n",
    "\n",
    "                for class_i in self.classes:\n",
    "                    # Retrieve reference signal for class i\n",
    "                    # (shape: n_chans, n_samples)\n",
    "                    traindata = np.squeeze(self.trains[class_i, fb_i])\n",
    "                    if self.ensemble:\n",
    "                        # shape = (n_chans, n_classes)\n",
    "                        w = np.squeeze(self.coef_[fb_i]).T\n",
    "                    else:\n",
    "                        # shape = (n_chans)\n",
    "                        w = np.squeeze(self.coef_[fb_i, class_i])\n",
    "\n",
    "                    # Compute 2D correlation of spatially filtered test data\n",
    "                    # with ref\n",
    "                    r_tmp = np.corrcoef((testdata @ w).flatten(),\n",
    "                                        (traindata @ w).flatten())\n",
    "                    r[fb_i, class_i] = r_tmp[0, 1]\n",
    "\n",
    "            rho = np.dot(fb_coefs, r)  # fusion for the filterbank analysis\n",
    "\n",
    "            tau = np.argmax(rho)  # retrieving index of the max\n",
    "            pred[trial] = int(tau)\n",
    "\n",
    "        return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2010)\n",
      "(9, 2009)\n",
      "(9, 2002)\n",
      "(9, 2008)\n",
      "(9, 2018)\n",
      "(9, 2016)\n",
      "(9, 2007)\n",
      "(9, 2007)\n",
      "(9, 2010)\n",
      "(9, 2005)\n",
      "(9, 2016)\n",
      "(9, 2007)\n",
      "(9, 2006)\n",
      "(9, 2019)\n",
      "(9, 2010)\n",
      "(9, 2009)\n",
      "(9, 2016)\n",
      "(9, 2003)\n",
      "(9, 2011)\n",
      "(9, 2018)\n",
      "(9, 2005)\n",
      "(9, 2005)\n",
      "(9, 2006)\n",
      "(9, 2009)\n",
      "(9, 2007)\n",
      "(9, 2002)\n",
      "(9, 2003)\n",
      "(9, 2012)\n",
      "(9, 2005)\n",
      "(9, 2005)\n",
      "(9, 2005)\n",
      "(9, 2018)\n",
      "(32, 8, 1750) (32,)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "from scipy import signal\n",
    "\n",
    "BOARD_ID = 8\n",
    "loaded_model = pickle.load(open(r\"C:\\Users\\bci\\Documents\\projects\\hybrid-ssvep-p300-speller\\hybrid\\nakanishi_TRCA_model.sav\", 'rb'))\n",
    "# pickle_files = glob(r'E:\\Thesis\\HybridSpeller\\nine_flicker\\record\\farheen_20230427_v2\\*.pickle')\n",
    "pickle_files = glob(r'C:\\Users\\bci\\Documents\\projects\\hybrid-ssvep-p300-speller\\hybrid\\record\\sunsun_20230523_2sec_0.5_overlap_12Hz\\*.pickle')\n",
    "\n",
    "y_pickle = []\n",
    "X_pickle = []\n",
    "for fpath in pickle_files:\n",
    "    _,filename = os.path.split(fpath)\n",
    "    y_pickle.append(filename[1])\n",
    "\n",
    "    with open(fpath, 'rb') as handle:\n",
    "        pickle_data = pickle.load(handle)\n",
    "\n",
    "    marker_channel = BoardShim.get_marker_channel(BOARD_ID)\n",
    "    eeg_channels = BoardShim.get_eeg_channels(BOARD_ID)\n",
    "    pickle_data[eeg_channels] = pickle_data[eeg_channels] / 1e6\n",
    "    pickle_data = pickle_data[eeg_channels + [marker_channel]]\n",
    "    print(pickle_data.shape)\n",
    "\n",
    "    _CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "\n",
    "    data = pickle_data[:8,:1750]\n",
    "\n",
    "\n",
    "    b,a = signal.iirfilter(7, Wn=[1, 92], rp=0.5, btype='band', analog=False, fs=250,  ftype='cheby1')\n",
    "    data = signal.filtfilt(b,a,data,axis=1)\n",
    "\n",
    "    notch_freq = 50\n",
    "    quality = 1\n",
    "    b,a = signal.iirnotch(notch_freq, quality, fs=250)\n",
    "    for i in range(3):\n",
    "        data[i] = signal.lfilter(b, a, data[i])\n",
    "\n",
    "    X_pickle.append(np.expand_dims(data[:],axis=0))\n",
    "\n",
    "y_pickle = np.array(y_pickle)\n",
    "X_pickle = np.concatenate(X_pickle)\n",
    "\n",
    "print(X_pickle.shape, y_pickle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8, 1750)\n"
     ]
    }
   ],
   "source": [
    "print(X_pickle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 8, 32)\n",
      "0 0.1875\n",
      "1 0.25\n",
      "2 0.15625\n",
      "3 0.125\n",
      "4 0.125\n",
      "5 0.125\n",
      "6 0.125\n",
      "7 0.0625\n",
      "8 0.09375\n",
      "9 0.0625\n",
      "10 0.09375\n",
      "11 0.03125\n",
      "12 0.03125\n",
      "13 0.09375\n",
      "14 0.03125\n",
      "15 0.15625\n",
      "16 0.25\n",
      "17 0.1875\n",
      "18 0.1875\n",
      "19 0.28125\n",
      "20 0.3125\n",
      "21 0.3125\n",
      "22 0.1875\n",
      "23 0.09375\n",
      "24 0.1875\n",
      "25 0.15625\n",
      "26 0.21875\n",
      "27 0.1875\n",
      "28 0.03125\n",
      "29 0.09375\n",
      "30 0.0625\n",
      "31 0.125\n",
      "32 0.09375\n",
      "33 0.125\n",
      "34 0.21875\n",
      "35 0.28125\n",
      "36 0.15625\n",
      "37 0.21875\n",
      "38 0.28125\n",
      "39 0.3125\n",
      "40 0.21875\n",
      "41 0.21875\n",
      "42 0.21875\n",
      "43 0.1875\n",
      "44 0.25\n",
      "45 0.15625\n",
      "46 0.15625\n",
      "47 0.125\n",
      "48 0.09375\n",
      "49 0.09375\n",
      "50 0.125\n",
      "51 0.15625\n",
      "52 0.15625\n",
      "53 0.125\n",
      "54 0.28125\n",
      "55 0.15625\n",
      "56 0.0625\n",
      "57 0.15625\n",
      "58 0.1875\n",
      "59 0.15625\n",
      "60 0.21875\n",
      "61 0.25\n",
      "62 0.15625\n",
      "63 0.15625\n",
      "64 0.21875\n",
      "65 0.21875\n",
      "66 0.1875\n",
      "67 0.1875\n",
      "68 0.1875\n",
      "69 0.09375\n",
      "70 0.125\n",
      "71 0.0625\n",
      "72 0.15625\n",
      "73 0.1875\n",
      "74 0.125\n",
      "75 0.15625\n",
      "76 0.09375\n",
      "77 0.1875\n",
      "78 0.125\n",
      "79 0.1875\n",
      "80 0.25\n",
      "81 0.21875\n",
      "82 0.15625\n",
      "83 0.09375\n",
      "84 0.1875\n",
      "85 0.15625\n",
      "86 0.15625\n",
      "87 0.1875\n",
      "88 0.1875\n",
      "89 0.1875\n",
      "90 0.1875\n",
      "91 0.1875\n",
      "92 0.21875\n",
      "93 0.21875\n",
      "94 0.15625\n",
      "95 0.21875\n",
      "96 0.21875\n",
      "97 0.125\n",
      "98 0.125\n",
      "99 0.15625\n",
      "100 0.1875\n",
      "101 0.15625\n",
      "102 0.0625\n",
      "103 0.0\n",
      "104 0.09375\n",
      "105 0.1875\n",
      "106 0.125\n",
      "107 0.125\n",
      "108 0.21875\n",
      "109 0.21875\n",
      "110 0.21875\n",
      "111 0.25\n",
      "112 0.09375\n",
      "113 0.1875\n",
      "114 0.15625\n",
      "115 0.15625\n",
      "116 0.125\n",
      "117 0.21875\n",
      "118 0.15625\n",
      "119 0.125\n",
      "120 0.125\n",
      "121 0.1875\n",
      "122 0.25\n",
      "123 0.125\n",
      "124 0.125\n",
      "125 0.21875\n",
      "126 0.125\n",
      "127 0.15625\n",
      "128 0.1875\n",
      "129 0.09375\n",
      "130 0.15625\n",
      "131 0.21875\n",
      "132 0.15625\n",
      "133 0.1875\n",
      "134 0.1875\n",
      "135 0.1875\n",
      "136 0.15625\n",
      "137 0.1875\n",
      "138 0.1875\n",
      "139 0.15625\n",
      "140 0.15625\n",
      "141 0.1875\n",
      "142 0.1875\n",
      "143 0.1875\n",
      "144 0.15625\n",
      "145 0.1875\n",
      "146 0.15625\n",
      "147 0.1875\n",
      "148 0.1875\n",
      "149 0.125\n",
      "150 0.1875\n",
      "151 0.25\n",
      "152 0.125\n",
      "153 0.15625\n",
      "154 0.09375\n",
      "155 0.0625\n",
      "156 0.15625\n",
      "157 0.15625\n",
      "158 0.15625\n",
      "159 0.15625\n",
      "160 0.15625\n",
      "161 0.1875\n",
      "162 0.15625\n",
      "163 0.09375\n",
      "164 0.15625\n",
      "165 0.21875\n",
      "166 0.25\n",
      "167 0.28125\n",
      "168 0.28125\n",
      "169 0.25\n",
      "170 0.34375\n",
      "171 0.25\n",
      "172 0.125\n",
      "173 0.1875\n",
      "174 0.125\n",
      "175 0.125\n",
      "176 0.15625\n",
      "177 0.125\n",
      "178 0.09375\n",
      "179 0.125\n",
      "180 0.09375\n",
      "181 0.09375\n",
      "182 0.125\n",
      "183 0.21875\n",
      "184 0.3125\n",
      "185 0.34375\n",
      "186 0.375\n",
      "187 0.40625\n",
      "188 0.34375\n",
      "189 0.25\n",
      "190 0.25\n",
      "191 0.21875\n",
      "192 0.21875\n",
      "193 0.125\n",
      "194 0.09375\n",
      "195 0.0625\n",
      "196 0.09375\n",
      "197 0.09375\n",
      "198 0.09375\n",
      "199 0.125\n",
      "200 0.09375\n",
      "201 0.15625\n",
      "202 0.28125\n",
      "203 0.40625\n",
      "204 0.4375\n",
      "205 0.4375\n",
      "206 0.4375\n",
      "207 0.40625\n",
      "208 0.40625\n",
      "209 0.3125\n",
      "210 0.34375\n",
      "211 0.25\n",
      "212 0.1875\n",
      "213 0.125\n",
      "214 0.0625\n",
      "215 0.03125\n",
      "216 0.09375\n",
      "217 0.09375\n",
      "218 0.15625\n",
      "219 0.3125\n",
      "220 0.28125\n",
      "221 0.4375\n",
      "222 0.4375\n",
      "223 0.53125\n",
      "224 0.625\n",
      "225 0.625\n",
      "226 0.59375\n",
      "227 0.5\n",
      "228 0.46875\n",
      "229 0.3125\n",
      "230 0.34375\n",
      "231 0.28125\n",
      "232 0.15625\n",
      "233 0.15625\n",
      "234 0.125\n",
      "235 0.125\n",
      "236 0.09375\n",
      "237 0.125\n",
      "238 0.15625\n",
      "239 0.25\n",
      "240 0.34375\n",
      "241 0.40625\n",
      "242 0.4375\n",
      "243 0.375\n",
      "244 0.5\n",
      "245 0.5\n",
      "246 0.3125\n",
      "247 0.34375\n",
      "248 0.21875\n",
      "249 0.25\n",
      "250 0.3125\n",
      "251 0.25\n",
      "252 0.15625\n",
      "253 0.1875\n",
      "254 0.1875\n",
      "255 0.125\n",
      "256 0.1875\n",
      "257 0.125\n",
      "258 0.1875\n",
      "259 0.28125\n",
      "260 0.34375\n",
      "261 0.3125\n",
      "262 0.28125\n",
      "263 0.28125\n",
      "264 0.25\n",
      "265 0.34375\n",
      "266 0.125\n",
      "267 0.125\n",
      "268 0.21875\n",
      "269 0.1875\n",
      "270 0.1875\n",
      "271 0.09375\n",
      "272 0.09375\n",
      "273 0.15625\n",
      "274 0.21875\n",
      "275 0.125\n",
      "276 0.28125\n",
      "277 0.28125\n",
      "278 0.3125\n",
      "279 0.25\n",
      "280 0.21875\n",
      "281 0.28125\n",
      "282 0.28125\n",
      "283 0.21875\n",
      "284 0.125\n",
      "285 0.1875\n",
      "286 0.1875\n",
      "287 0.125\n",
      "288 0.15625\n",
      "289 0.15625\n",
      "290 0.1875\n",
      "291 0.15625\n",
      "292 0.125\n",
      "293 0.15625\n",
      "294 0.1875\n",
      "295 0.21875\n",
      "296 0.25\n",
      "297 0.1875\n",
      "298 0.21875\n",
      "299 0.15625\n",
      "300 0.125\n",
      "301 0.1875\n",
      "302 0.15625\n",
      "303 0.09375\n",
      "304 0.09375\n",
      "305 0.21875\n",
      "306 0.21875\n",
      "307 0.09375\n",
      "308 0.21875\n",
      "309 0.15625\n",
      "310 0.25\n",
      "311 0.25\n",
      "312 0.1875\n",
      "313 0.15625\n",
      "314 0.21875\n",
      "315 0.15625\n",
      "316 0.1875\n",
      "317 0.1875\n",
      "318 0.1875\n",
      "319 0.1875\n",
      "320 0.09375\n",
      "321 0.125\n",
      "322 0.0625\n",
      "323 0.15625\n",
      "324 0.125\n",
      "325 0.21875\n",
      "326 0.1875\n",
      "327 0.1875\n",
      "328 0.25\n",
      "329 0.28125\n",
      "330 0.34375\n",
      "331 0.3125\n",
      "332 0.28125\n",
      "333 0.09375\n",
      "334 0.1875\n",
      "335 0.15625\n",
      "336 0.1875\n",
      "337 0.15625\n",
      "338 0.15625\n",
      "339 0.125\n",
      "340 0.25\n",
      "341 0.25\n",
      "342 0.15625\n",
      "343 0.1875\n",
      "344 0.1875\n",
      "345 0.28125\n",
      "346 0.4375\n",
      "347 0.34375\n",
      "348 0.28125\n",
      "349 0.21875\n",
      "350 0.21875\n",
      "351 0.21875\n",
      "352 0.15625\n",
      "353 0.15625\n",
      "354 0.21875\n",
      "355 0.125\n",
      "356 0.125\n",
      "357 0.21875\n",
      "358 0.15625\n",
      "359 0.21875\n",
      "360 0.25\n",
      "361 0.1875\n",
      "362 0.3125\n",
      "363 0.28125\n",
      "364 0.21875\n",
      "365 0.3125\n",
      "366 0.34375\n",
      "367 0.15625\n",
      "368 0.21875\n",
      "369 0.15625\n",
      "370 0.125\n",
      "371 0.125\n",
      "372 0.09375\n",
      "373 0.125\n",
      "374 0.15625\n",
      "375 0.1875\n",
      "376 0.1875\n",
      "377 0.15625\n",
      "378 0.25\n",
      "379 0.25\n",
      "380 0.25\n",
      "381 0.25\n",
      "382 0.25\n",
      "383 0.28125\n",
      "384 0.21875\n",
      "385 0.25\n",
      "386 0.25\n",
      "387 0.15625\n",
      "388 0.0625\n",
      "389 0.0625\n",
      "390 0.125\n",
      "391 0.0625\n",
      "392 0.09375\n",
      "393 0.15625\n",
      "394 0.1875\n",
      "395 0.15625\n",
      "396 0.25\n",
      "397 0.25\n",
      "398 0.28125\n",
      "399 0.21875\n",
      "400 0.34375\n",
      "401 0.34375\n",
      "402 0.25\n",
      "403 0.1875\n",
      "404 0.21875\n",
      "405 0.21875\n",
      "406 0.15625\n",
      "407 0.0625\n",
      "408 0.09375\n",
      "409 0.03125\n",
      "410 0.15625\n",
      "411 0.15625\n",
      "412 0.15625\n",
      "413 0.15625\n",
      "414 0.21875\n",
      "415 0.15625\n",
      "416 0.21875\n",
      "417 0.21875\n",
      "418 0.1875\n",
      "419 0.1875\n",
      "420 0.28125\n",
      "421 0.28125\n",
      "422 0.1875\n",
      "423 0.09375\n",
      "424 0.09375\n",
      "425 0.125\n",
      "426 0.15625\n",
      "427 0.09375\n",
      "428 0.09375\n",
      "429 0.125\n",
      "430 0.21875\n",
      "431 0.21875\n",
      "432 0.125\n",
      "433 0.125\n",
      "434 0.1875\n",
      "435 0.25\n",
      "436 0.25\n",
      "437 0.3125\n",
      "438 0.1875\n",
      "439 0.25\n",
      "440 0.21875\n",
      "441 0.09375\n",
      "442 0.0625\n",
      "443 0.09375\n",
      "444 0.0625\n",
      "445 0.09375\n",
      "446 0.0625\n",
      "447 0.125\n",
      "448 0.09375\n",
      "449 0.09375\n",
      "450 0.1875\n",
      "451 0.1875\n",
      "452 0.28125\n",
      "453 0.28125\n",
      "454 0.15625\n",
      "455 0.25\n",
      "456 0.3125\n",
      "457 0.21875\n",
      "458 0.1875\n",
      "459 0.0625\n",
      "460 0.09375\n",
      "461 0.09375\n",
      "462 0.03125\n",
      "463 0.03125\n",
      "464 0.03125\n",
      "465 0.125\n",
      "466 0.125\n",
      "467 0.15625\n",
      "468 0.1875\n",
      "469 0.21875\n",
      "470 0.25\n",
      "471 0.1875\n",
      "472 0.15625\n",
      "473 0.125\n",
      "474 0.09375\n",
      "475 0.125\n",
      "476 0.125\n",
      "477 0.0625\n",
      "478 0.09375\n",
      "479 0.0625\n",
      "480 0.0625\n",
      "481 0.03125\n",
      "482 0.0625\n",
      "483 0.09375\n",
      "484 0.09375\n",
      "485 0.125\n",
      "486 0.0625\n",
      "487 0.09375\n",
      "488 0.1875\n",
      "489 0.15625\n",
      "490 0.21875\n",
      "491 0.15625\n",
      "492 0.15625\n",
      "493 0.09375\n",
      "494 0.09375\n",
      "495 0.125\n",
      "496 0.09375\n",
      "497 0.09375\n",
      "498 0.09375\n",
      "499 0.125\n"
     ]
    }
   ],
   "source": [
    "best_predict = None\n",
    "best_score = 0\n",
    "X_pickle = np.swapaxes(X_pickle,0,2)\n",
    "print(X_pickle.shape)\n",
    "for r in range(500):\n",
    "    offset = int(r)\n",
    "    # offset = int(r)\n",
    "    preds_pickle = loaded_model.predict(X_pickle[offset:offset + 1250,:,:])\n",
    "    # print(preds_pickle)\n",
    "    # print(y_pickle)\n",
    "    # print(X_pickle[:,:,offset:offset + 750].shape)\n",
    "    c = 0\n",
    "    preds_pickle_converted = []\n",
    "    for idx in range(len(preds_pickle)):\n",
    "        pred = preds_pickle[idx]\n",
    "        label = y_pickle[idx]\n",
    "        if(pred == 0):\n",
    "            pred = 'A'\n",
    "        if(pred == 1):\n",
    "            pred = 'B'\n",
    "        if(pred == 2):\n",
    "            pred = 'C'\n",
    "        if(pred == 3):\n",
    "            pred = 'D'\n",
    "        if(pred == 4):\n",
    "            pred = 'E'\n",
    "        if(pred == 5):\n",
    "            pred = 'F'\n",
    "        if(pred == 6):\n",
    "            pred = 'G'\n",
    "        if(pred == 7):\n",
    "            pred = 'H'\n",
    "        if(pred == 8):\n",
    "            pred = 'I'\n",
    "        if(pred == 9):\n",
    "            pred = 'J'\n",
    "        if(pred == 10):\n",
    "            pred = 'K'\n",
    "        if(pred == 11):\n",
    "            pred = 'L'\n",
    "        if(pred == 12):\n",
    "            pred = 'M'\n",
    "        if(pred == 13):\n",
    "            pred = 'N'\n",
    "        if(pred == 14):\n",
    "            pred = 'O'\n",
    "        if(pred == 15):\n",
    "            pred = 'P'\n",
    "        if(label == pred):\n",
    "            c += 1\n",
    "        # print(idx, f\"{pred=} {label=}\" )\n",
    "    score = c/len(preds_pickle)\n",
    "    print(offset, score)\n",
    "    if(best_score < score):\n",
    "        best_score = score\n",
    "        best_predict = preds_pickle_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 8, 1750)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The length of the input vector x must be greater than padlen, which is 42.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m X_pickle \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mswapaxes(X_pickle,\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(X_pickle\u001b[39m.\u001b[39mshape)\n\u001b[1;32m----> 4\u001b[0m preds_pickle \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39;49mpredict(X_pickle[offset:offset \u001b[39m+\u001b[39;49m \u001b[39m1250\u001b[39;49m,:,:])\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(preds_pickle)\n\u001b[0;32m      6\u001b[0m \u001b[39m# print(y_pickle)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 151\u001b[0m, in \u001b[0;36mTRCA.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    147\u001b[0m test_tmp \u001b[39m=\u001b[39m X[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, trial]  \u001b[39m# pick a trial to be analysed\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[39mfor\u001b[39;00m fb_i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_bands):\n\u001b[0;32m    149\u001b[0m \n\u001b[0;32m    150\u001b[0m     \u001b[39m# filterbank on testdata\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m     testdata \u001b[39m=\u001b[39m bandpass(test_tmp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msfreq,\n\u001b[0;32m    152\u001b[0m                         Wp\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilterbank[fb_i][\u001b[39m0\u001b[39;49m],\n\u001b[0;32m    153\u001b[0m                         Ws\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilterbank[fb_i][\u001b[39m1\u001b[39;49m])\n\u001b[0;32m    155\u001b[0m     \u001b[39mfor\u001b[39;00m class_i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses:\n\u001b[0;32m    156\u001b[0m         \u001b[39m# Retrieve reference signal for class i\u001b[39;00m\n\u001b[0;32m    157\u001b[0m         \u001b[39m# (shape: n_chans, n_samples)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m         traindata \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrains[class_i, fb_i])\n",
      "Cell \u001b[1;32mIn[11], line 34\u001b[0m, in \u001b[0;36mbandpass\u001b[1;34m(eeg, sfreq, Wp, Ws)\u001b[0m\n\u001b[0;32m     30\u001b[0m B, A \u001b[39m=\u001b[39m cheby1(N, \u001b[39m0.5\u001b[39m, Wn, btype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbandpass\u001b[39m\u001b[39m\"\u001b[39m, fs\u001b[39m=\u001b[39msfreq)\n\u001b[0;32m     32\u001b[0m \u001b[39m# the arguments 'axis=0, padtype='odd', padlen=3*(max(len(B),len(A))-1)'\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[39m# correspond to Matlab filtfilt : https://dsp.stackexchange.com/a/47945\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m y \u001b[39m=\u001b[39m filtfilt(B, A, eeg, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, padtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39modd\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m     35\u001b[0m              padlen\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m \u001b[39m*\u001b[39;49m (\u001b[39mmax\u001b[39;49m(\u001b[39mlen\u001b[39;49m(B), \u001b[39mlen\u001b[39;49m(A)) \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m))\n\u001b[0;32m     36\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\bci\\.virtualenvs\\hybrid-ssvep-p300-speller-ZL_XZSnA\\lib\\site-packages\\scipy\\signal\\_signaltools.py:4130\u001b[0m, in \u001b[0;36mfiltfilt\u001b[1;34m(b, a, x, axis, padtype, padlen, method, irlen)\u001b[0m\n\u001b[0;32m   4127\u001b[0m     \u001b[39mreturn\u001b[39;00m y\n\u001b[0;32m   4129\u001b[0m \u001b[39m# method == \"pad\"\u001b[39;00m\n\u001b[1;32m-> 4130\u001b[0m edge, ext \u001b[39m=\u001b[39m _validate_pad(padtype, padlen, x, axis,\n\u001b[0;32m   4131\u001b[0m                           ntaps\u001b[39m=\u001b[39;49m\u001b[39mmax\u001b[39;49m(\u001b[39mlen\u001b[39;49m(a), \u001b[39mlen\u001b[39;49m(b)))\n\u001b[0;32m   4133\u001b[0m \u001b[39m# Get the steady state of the filter's step response.\u001b[39;00m\n\u001b[0;32m   4134\u001b[0m zi \u001b[39m=\u001b[39m lfilter_zi(b, a)\n",
      "File \u001b[1;32mc:\\Users\\bci\\.virtualenvs\\hybrid-ssvep-p300-speller-ZL_XZSnA\\lib\\site-packages\\scipy\\signal\\_signaltools.py:4180\u001b[0m, in \u001b[0;36m_validate_pad\u001b[1;34m(padtype, padlen, x, axis, ntaps)\u001b[0m\n\u001b[0;32m   4178\u001b[0m \u001b[39m# x's 'axis' dimension must be bigger than edge.\u001b[39;00m\n\u001b[0;32m   4179\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[axis] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m edge:\n\u001b[1;32m-> 4180\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe length of the input vector x must be greater \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4181\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mthan padlen, which is \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m edge)\n\u001b[0;32m   4183\u001b[0m \u001b[39mif\u001b[39;00m padtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m edge \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   4184\u001b[0m     \u001b[39m# Make an extension of length `edge` at each\u001b[39;00m\n\u001b[0;32m   4185\u001b[0m     \u001b[39m# end of the input array.\u001b[39;00m\n\u001b[0;32m   4186\u001b[0m     \u001b[39mif\u001b[39;00m padtype \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39meven\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: The length of the input vector x must be greater than padlen, which is 42."
     ]
    }
   ],
   "source": [
    "offset = 274\n",
    "X_pickle = np.swapaxes(X_pickle,0,2)\n",
    "print(X_pickle.shape)\n",
    "preds_pickle = loaded_model.predict(X_pickle[offset:offset + 1250,:,:])\n",
    "print(preds_pickle)\n",
    "# print(y_pickle)\n",
    "c = 0\n",
    "for idx in range(len(preds_pickle)):\n",
    "    pred = preds_pickle[idx]\n",
    "    label = y_pickle[idx]\n",
    "    if(pred == 0):\n",
    "        pred = 'A'\n",
    "    if(pred == 1):\n",
    "        pred = 'B'\n",
    "    if(pred == 2):\n",
    "        pred = 'C'\n",
    "    if(pred == 3):\n",
    "        pred = 'D'\n",
    "    if(pred == 4):\n",
    "        pred = 'E'\n",
    "    if(pred == 5):\n",
    "        pred = 'F'\n",
    "    if(pred == 6):\n",
    "        pred = 'G'\n",
    "    if(pred == 7):\n",
    "        pred = 'H'\n",
    "    if(pred == 8):\n",
    "        pred = 'I'\n",
    "    if(pred == 9):\n",
    "        pred = 'J'\n",
    "    if(pred == 10):\n",
    "        pred = 'K'\n",
    "    if(pred == 11):\n",
    "        pred = 'L'\n",
    "    if(pred == 12):\n",
    "        pred = 'M'\n",
    "    if(pred == 13):\n",
    "        pred = 'N'\n",
    "    if(pred == 14):\n",
    "        pred = 'O'\n",
    "    if(pred == 15):\n",
    "        pred = 'P'\n",
    "    if(label == pred):\n",
    "        c += 1\n",
    "    pred_ascii = ord(pred)-65\n",
    "    label_ascii = ord(label)-65\n",
    "    print(idx, f\"{pred=} {pred_ascii} {label=} {label_ascii}\" )\n",
    "print(c/len(preds_pickle)\n",
    "      )\n",
    "print(len(preds_pickle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HybridSpeller-q8UBACmb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
