{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  mne\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from numpy import ndarray\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.sparse import block_diag, identity, vstack, spmatrix\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import eigh, pinv, qr\n",
    "from typing import Optional, List, cast\n",
    "from functools import partial\n",
    "from scipy.signal import filtfilt, cheb1ord, cheby1\n",
    "import scipy.linalg as linalg\n",
    "from pyriemann.utils.mean import mean_covariance\n",
    "from pyriemann.estimation import Covariances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file E:\\Thesis\\HybridSpeller\\hybrid\\record\\manish_4target_20230517\\manish_4target_20230517.fif...\n",
      "    Range : 0 ... 449999 =      0.000 ...  1799.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 449999  =      0.000 ...  1799.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunsun\\AppData\\Local\\Temp\\ipykernel_4456\\2780239140.py:4: RuntimeWarning: This filename (E:\\Thesis\\HybridSpeller\\hybrid\\record\\manish_4target_20230517\\manish_4target_20230517.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw =  mne.io.read_raw_fif(fname,  preload = True)\n"
     ]
    }
   ],
   "source": [
    "# fname = r\"E:\\Thesis\\HybridSpeller\\hybrid\\record\\sunsun_4target_20230519_3sec\\sunsun_4target_20230519_3sec.fif\"\n",
    "fname = r\"E:\\Thesis\\HybridSpeller\\hybrid\\record\\manish_4target_20230517\\manish_4target_20230517.fif\"\n",
    "# fname = r\"E:\\Thesis\\HybridSpeller\\hybrid\\record\\count_test_15\\count_test_15.fif\"\n",
    "raw =  mne.io.read_raw_fif(fname,  preload = True)\n",
    "# new_data = raw.get_data()[:,10*250:-10*250]\n",
    "# raw_new = mne.io.RawArray(new_data, raw.info)\n",
    "# raw_new.notch_filter([50], trans_bandwidth = 3)\n",
    "# raw_new.filter(1,92)\n",
    "# raw_new.compute_psd().plot()\n",
    "# raw = raw_new\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 events found\n",
      "Event IDs: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "Using data from preloaded Raw for 218 events and 750 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "events = mne.find_events(raw, initial_event = True)\n",
    "tmin, tmax = 1,  4 - 1/250  # in s\n",
    "baseline = None\n",
    "epochs = mne.Epochs(\n",
    "    raw, events=events,tmin=tmin,\n",
    "    tmax=tmax, baseline=baseline, verbose=False)\n",
    "\n",
    "X = epochs.get_data()[:, :-1, :]\n",
    "y = epochs.events[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15 12  7 14  5  0  8 13 10  4 10  8  9  1 11 14 15  5 12  0  4 13  3  7\n",
      "  2  6  2  9  8 15  7  4  0 13 14  5 10  6  3  1 11 12 11  4  6 15  5  8\n",
      " 13  7  3 10 14 12  2  0  1  9  9  1 14 12  5  3 11 15 13  6  8 10  4  2\n",
      "  0  7  2  3 14 12  9  4  1 13 10 11  5 15  8  7  6  0  1  6 11  4  3 10\n",
      "  8 14  5 15  7 12  2 13  9  0  3  1  8 14  2 15 12 11 13 10  5  7  9  0\n",
      "  6  4  0  3  9 15  4 11 10 14  1 13  2  5  8  6  7 12 10 14  3 13  1  5\n",
      "  9  0  4  2  6 11 12  7  8 15 11  3 10 14 15  6  1 13 12  4  5  7  2  8\n",
      "  9  0  7 13  5  4 11  3  0 15 14  9 12  2 10  1  6  8  7  5  3 14  1  8\n",
      " 12  6  2 15  4 11 13  0 10  9  8  9  2  3  6  4 15  0  7  5 12  1 11 14\n",
      " 13 10]\n"
     ]
    }
   ],
   "source": [
    "y = y - 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15] [14 13 13 13 14 14 13 14 14 13 14 13 14 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "values, counts = np.unique(y, return_counts=True)\n",
    "print(values, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748 0 2337 1 1589\n",
      "2337 1 3931 2 1594\n",
      "3931 2 5523 3 1592\n",
      "5523 3 7117 4 1594\n",
      "7117 4 8708 5 1591\n",
      "8708 5 10304 6 1596\n",
      "10304 6 11898 7 1594\n",
      "11898 7 13496 8 1598\n",
      "13496 8 15087 9 1591\n",
      "15087 9 24524 10 9437\n",
      "24524 10 26127 11 1603\n",
      "26127 11 27716 12 1589\n",
      "27716 12 29320 13 1604\n",
      "29320 13 30911 14 1591\n",
      "30911 14 32512 15 1601\n",
      "32512 15 34105 16 1593\n",
      "34105 16 35699 17 1594\n",
      "35699 17 37291 18 1592\n",
      "37291 18 38883 19 1592\n",
      "38883 19 40485 20 1602\n",
      "40485 20 42077 21 1592\n",
      "42077 21 43671 22 1594\n",
      "43671 22 45262 23 1591\n",
      "45262 23 46876 24 1614\n",
      "46876 24 48468 25 1592\n",
      "48468 25 57901 26 9433\n",
      "57901 26 59500 27 1599\n",
      "59500 27 61099 28 1599\n",
      "61099 28 62694 29 1595\n",
      "62694 29 64286 30 1592\n",
      "64286 30 65880 31 1594\n",
      "65880 31 67475 32 1595\n",
      "67475 32 69068 33 1593\n",
      "69068 33 70657 34 1589\n",
      "70657 34 72249 35 1592\n",
      "72249 35 73846 36 1597\n",
      "73846 36 75446 37 1600\n",
      "75446 37 77039 38 1593\n",
      "77039 38 78632 39 1593\n",
      "78632 39 80220 40 1588\n",
      "80220 40 81820 41 1600\n",
      "81820 41 91263 42 9443\n",
      "91263 42 92854 43 1591\n",
      "92854 43 94445 44 1591\n",
      "94445 44 96039 45 1594\n",
      "96039 45 97628 46 1589\n",
      "97628 46 99218 47 1590\n",
      "99218 47 100821 48 1603\n",
      "100821 48 102421 49 1600\n",
      "102421 49 104015 50 1594\n",
      "104015 50 105606 51 1591\n",
      "105606 51 107211 52 1605\n",
      "107211 52 108804 53 1593\n",
      "108804 53 110394 54 1590\n",
      "110394 54 111980 55 1586\n",
      "111980 55 113573 56 1593\n",
      "113573 56 115171 57 1598\n",
      "115171 57 124613 58 9442\n",
      "124613 58 126205 59 1592\n",
      "126205 59 127796 60 1591\n",
      "127796 60 129393 61 1597\n",
      "129393 61 130991 62 1598\n",
      "130991 62 132590 63 1599\n",
      "132590 63 134182 64 1592\n",
      "134182 64 135774 65 1592\n",
      "135774 65 137368 66 1594\n",
      "137368 66 138960 67 1592\n",
      "138960 67 140554 68 1594\n",
      "140554 68 142146 69 1592\n",
      "142146 69 143740 70 1594\n",
      "143740 70 145340 71 1600\n",
      "145340 71 146932 72 1592\n",
      "146932 72 148532 73 1600\n",
      "148532 73 157966 74 9434\n",
      "157966 74 159564 75 1598\n",
      "159564 75 161157 76 1593\n",
      "161157 76 162748 77 1591\n",
      "162748 77 164342 78 1594\n",
      "164342 78 165934 79 1592\n",
      "165934 79 167526 80 1592\n",
      "167526 80 169119 81 1593\n",
      "169119 81 170712 82 1593\n",
      "170712 82 172308 83 1596\n",
      "172308 83 173901 84 1593\n",
      "173901 84 175492 85 1591\n",
      "175492 85 177078 86 1586\n",
      "177078 86 178670 87 1592\n",
      "178670 87 180260 88 1590\n",
      "180260 88 181859 89 1599\n",
      "181859 89 191297 90 9438\n",
      "191297 90 192886 91 1589\n",
      "192886 91 194479 92 1593\n",
      "194479 92 196067 93 1588\n",
      "196067 93 197658 94 1591\n",
      "197658 94 199257 95 1599\n",
      "199257 95 200844 96 1587\n",
      "200844 96 202441 97 1597\n",
      "202441 97 204034 98 1593\n",
      "204034 98 205625 99 1591\n",
      "205625 99 207219 100 1594\n",
      "207219 100 208815 101 1596\n",
      "208815 101 210412 102 1597\n",
      "210412 102 212010 103 1598\n",
      "212010 103 213602 104 1592\n",
      "213602 104 215198 105 1596\n",
      "215198 105 224637 106 9439\n",
      "224637 106 226232 107 1595\n",
      "226232 107 227817 108 1585\n",
      "227817 108 229415 109 1598\n",
      "229415 109 231016 110 1601\n",
      "231016 110 232612 111 1596\n",
      "232612 111 234206 112 1594\n",
      "234206 112 235798 113 1592\n",
      "235798 113 237392 114 1594\n",
      "237392 114 238984 115 1592\n",
      "238984 115 240584 116 1600\n",
      "240584 116 242177 117 1593\n",
      "242177 117 243767 118 1590\n",
      "243767 118 245363 119 1596\n",
      "245363 119 246958 120 1595\n",
      "246958 120 248556 121 1598\n",
      "248556 121 257995 122 9439\n",
      "257995 122 259584 123 1589\n",
      "259584 123 261180 124 1596\n",
      "261180 124 262772 125 1592\n",
      "262772 125 264374 126 1602\n",
      "264374 126 265965 127 1591\n",
      "265965 127 267562 128 1597\n",
      "267562 128 269156 129 1594\n",
      "269156 129 270746 130 1590\n",
      "270746 130 272339 131 1593\n",
      "272339 131 273941 132 1602\n",
      "273941 132 275538 133 1597\n",
      "275538 133 277134 134 1596\n",
      "277134 134 278728 135 1594\n",
      "278728 135 280320 136 1592\n",
      "280320 136 281910 137 1590\n",
      "281910 137 291351 138 9441\n",
      "291351 138 292947 139 1596\n",
      "292947 139 294541 140 1594\n",
      "294541 140 296136 141 1595\n",
      "296136 141 297732 142 1596\n",
      "297732 142 299329 143 1597\n",
      "299329 143 300923 144 1594\n",
      "300923 144 302515 145 1592\n",
      "302515 145 304104 146 1589\n",
      "304104 146 305691 147 1587\n",
      "305691 147 307286 148 1595\n",
      "307286 148 308878 149 1592\n",
      "308878 149 310483 150 1605\n",
      "310483 150 312074 151 1591\n",
      "312074 151 313668 152 1594\n",
      "313668 152 315266 153 1598\n",
      "315266 153 324698 154 9432\n",
      "324698 154 326286 155 1588\n",
      "326286 155 327885 156 1599\n",
      "327885 156 329475 157 1590\n",
      "329475 157 331071 158 1596\n",
      "331071 158 332665 159 1594\n",
      "332665 159 334253 160 1588\n",
      "334253 160 335845 161 1592\n",
      "335845 161 337437 162 1592\n",
      "337437 162 339030 163 1593\n",
      "339030 163 340617 164 1587\n",
      "340617 164 342211 165 1594\n",
      "342211 165 343812 166 1601\n",
      "343812 166 345409 167 1597\n",
      "345409 167 347005 168 1596\n",
      "347005 168 348606 169 1601\n",
      "348606 169 358043 170 9437\n",
      "358043 170 359631 171 1588\n",
      "359631 171 361225 172 1594\n",
      "361225 172 362816 173 1591\n",
      "362816 173 364408 174 1592\n",
      "364408 174 365998 175 1590\n",
      "365998 175 367596 176 1598\n",
      "367596 176 369189 177 1593\n",
      "369189 177 370779 178 1590\n",
      "370779 178 372370 179 1591\n",
      "372370 179 373962 180 1592\n",
      "373962 180 375562 181 1600\n",
      "375562 181 377154 182 1592\n",
      "377154 182 378751 183 1597\n",
      "378751 183 380344 184 1593\n",
      "380344 184 381942 185 1598\n",
      "381942 185 391385 186 9443\n",
      "391385 186 392977 187 1592\n",
      "392977 187 394567 188 1590\n",
      "394567 188 396166 189 1599\n",
      "396166 189 397758 190 1592\n",
      "397758 190 399351 191 1593\n",
      "399351 191 400942 192 1591\n",
      "400942 192 402539 193 1597\n",
      "402539 193 404131 194 1592\n",
      "404131 194 405732 195 1601\n",
      "405732 195 407327 196 1595\n",
      "407327 196 408922 197 1595\n",
      "408922 197 410519 198 1597\n",
      "410519 198 412118 199 1599\n",
      "412118 199 413710 200 1592\n",
      "413710 200 415303 201 1593\n",
      "415303 201 424739 202 9436\n",
      "424739 202 426330 203 1591\n",
      "426330 203 427921 204 1591\n",
      "427921 204 429514 205 1593\n",
      "429514 205 431106 206 1592\n",
      "431106 206 432698 207 1592\n",
      "432698 207 434291 208 1593\n",
      "434291 208 435883 209 1592\n",
      "435883 209 437478 210 1595\n",
      "437478 210 439072 211 1594\n",
      "439072 211 440668 212 1596\n",
      "440668 212 442260 213 1592\n",
      "442260 213 443865 214 1605\n",
      "443865 214 445461 215 1596\n",
      "445461 215 447058 216 1597\n",
      "447058 216 448648 217 1590\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(events[:,0]) -1 ):\n",
    "    t1 = events[:,0][i]\n",
    "    t2 = events[:,0][i+1]\n",
    "    print(t1,i,t2,i+1, t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(252, 8, 750)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfreq = 250\n",
    "is_ensemble = True\n",
    "\n",
    "# filterbank = [[(1, 92), (0, 100)],  # passband, stopband freqs [(Wp), (Ws)]\n",
    "#               [(11, 92), (10, 100)],\n",
    "#               [(22, 92), (16, 100)],\n",
    "#               [(34, 92), (24, 100)],\n",
    "#               [(46, 92), (32, 100)],\n",
    "#               [(58, 92), (40, 100)],\n",
    "#               [(70, 92), (48, 100)],\n",
    "#               [(82, 92), (52, 100)]]\n",
    "filterbank = [[(1, 92), (0, 100)],  # passband, stopband freqs [(Wp), (Ws)]\n",
    "               [(7, 92), (6, 100)],\n",
    "               [(14, 92), (10, 100)],\n",
    "               [(22, 92), (18, 100)],\n",
    "               [(30, 92), (26, 100)],\n",
    "               [(38, 92), (32, 100)],\n",
    "               [(46, 92), (40, 100)],\n",
    "               [(54, 92), (46, 100)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_data(X):\n",
    "    \"\"\"Check data is numpy array and has the proper dimensions.\"\"\"\n",
    "    if not isinstance(X, (np.ndarray, list)):\n",
    "        raise AttributeError('data should be a list or a numpy array')\n",
    "\n",
    "    dtype = np.complex128 if np.any(np.iscomplex(X)) else np.float64\n",
    "    X = np.asanyarray(X, dtype=dtype)\n",
    "    if X.ndim > 3:\n",
    "        raise ValueError('Data must be 3D at most')\n",
    "\n",
    "    return X\n",
    "\n",
    "def theshapeof(X):\n",
    "    \"\"\"Return the shape of X.\"\"\"\n",
    "    X = _check_data(X)\n",
    "    # if not isinstance(X, np.ndarray):\n",
    "    #     raise AttributeError('X must be a numpy array')\n",
    "\n",
    "    if X.ndim == 3:\n",
    "        return X.shape[0], X.shape[1], X.shape[2]\n",
    "    elif X.ndim == 2:\n",
    "        return X.shape[0], X.shape[1], 1\n",
    "    elif X.ndim == 1:\n",
    "        return X.shape[0], 1, 1\n",
    "    else:\n",
    "        raise ValueError(\"Array contains more than 3 dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandpass(eeg, sfreq, Wp, Ws):\n",
    "    \"\"\"Filter bank design for decomposing EEG data into sub-band components.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eeg : np.array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "    sfreq : int\n",
    "        Sampling frequency of the data.\n",
    "    Wp : 2-tuple\n",
    "        Passband for Chebyshev filter.\n",
    "    Ws : 2-tuple\n",
    "        Stopband for Chebyshev filter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y: np.array, shape=(n_trials, n_chans, n_samples)\n",
    "        Sub-band components decomposed by a filter bank.\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    scipy.signal.cheb1ord :\n",
    "        Chebyshev type I filter order selection.\n",
    "\n",
    "    \"\"\"\n",
    "    # Chebyshev type I filter order selection.\n",
    "    N, Wn = cheb1ord(Wp, Ws, 3, 40, fs=sfreq)\n",
    "\n",
    "    # Chebyshev type I filter design\n",
    "    B, A = cheby1(N, 0.5, Wn, btype=\"bandpass\", fs=sfreq)\n",
    "\n",
    "    # the arguments 'axis=0, padtype='odd', padlen=3*(max(len(B),len(A))-1)'\n",
    "    # correspond to Matlab filtfilt : https://dsp.stackexchange.com/a/47945\n",
    "    y = filtfilt(B, A, eeg, axis=0, padtype='odd',\n",
    "                 padlen=3 * (max(len(B), len(A)) - 1))\n",
    "    return y\n",
    "\n",
    "\n",
    "def schaefer_strimmer_cov(X):\n",
    "    r\"\"\"Schaefer-Strimmer covariance estimator.\n",
    "\n",
    "    Shrinkage estimator described in [1]_:\n",
    "\n",
    "    .. math:: \\hat{\\Sigma} = (1 - \\gamma)\\Sigma_{scm} + \\gamma T\n",
    "\n",
    "    where :math:`T` is the diagonal target matrix:\n",
    "\n",
    "    .. math:: T_{i,j} = \\{ \\Sigma_{scm}^{ii} \\text{if} i = j,\n",
    "         0 \\text{otherwise} \\}\n",
    "\n",
    "    Note that the optimal :math:`\\gamma` is estimated by the authors' method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: array, shape=(n_chans, n_samples)\n",
    "        Signal matrix.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cov: array, shape=(n_chans, n_chans)\n",
    "        Schaefer-Strimmer shrinkage covariance matrix.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Schafer, J., and K. Strimmer. 2005. A shrinkage approach to\n",
    "       large-scale covariance estimation and implications for functional\n",
    "       genomics. Statist. Appl. Genet. Mol. Biol. 4:32.\n",
    "    \"\"\"\n",
    "    ns = X.shape[1]\n",
    "    C_scm = np.cov(X, ddof=0)\n",
    "    X_c = X - np.tile(X.mean(axis=1), [ns, 1]).T\n",
    "\n",
    "    # Compute optimal gamma, the weigthing between SCM and srinkage estimator\n",
    "    R = ns / (ns - 1.0) * np.corrcoef(X)\n",
    "    var_R = (X_c ** 2).dot((X_c ** 2).T) - 2 * C_scm * X_c.dot(X_c.T)\n",
    "    var_R += ns * C_scm ** 2\n",
    "\n",
    "    var_R = ns / ((ns - 1) ** 3 * np.outer(X.var(1), X.var(1))) * var_R\n",
    "    R -= np.diag(np.diag(R))\n",
    "    var_R -= np.diag(np.diag(var_R))\n",
    "    gamma = max(0, min(1, var_R.sum() / (R ** 2).sum()))\n",
    "\n",
    "    cov = (1. - gamma) * (ns / (ns - 1.)) * C_scm\n",
    "    cov += gamma * (ns / (ns - 1.)) * np.diag(np.diag(C_scm))\n",
    "\n",
    "    return cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _trca(X):\n",
    "    \"\"\"Task-related component analysis.\n",
    "\n",
    "    This function implements the method described in [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    W : array, shape=(n_chans,)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Covariance\n",
    "    Q = UX @ UX.T\n",
    "\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    S = np.zeros((n_chans, n_chans))\n",
    "    for trial_i in range(n_trials - 1):\n",
    "        x1 = np.squeeze(X[..., trial_i])\n",
    "\n",
    "        # Mean centering for the selected trial\n",
    "        x1 -= np.mean(x1, 0)\n",
    "\n",
    "        # Select a second trial that is different\n",
    "        for trial_j in range(trial_i + 1, n_trials):\n",
    "            x2 = np.squeeze(X[..., trial_j])\n",
    "\n",
    "            # Mean centering for the selected trial\n",
    "            x2 -= np.mean(x2, 0)\n",
    "\n",
    "            # Compute empirical covariance between the two selected trials and\n",
    "            # sum it\n",
    "            S = S + x1.T @ x2 + x2.T @ x1\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best\n",
    "\n",
    "\n",
    "def trca_regul(X, method):\n",
    "    \"\"\"Task-related component analysis.\n",
    "\n",
    "    This function implements a variation of the method described in [1]_. It is\n",
    "    inspired by a riemannian geometry approach to CSP [2]_. It adds\n",
    "    regularization to the covariance matrices and uses the riemannian mean for\n",
    "    the inter-trial covariance matrix `S`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "        Training data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    W : array, shape=(n_chans,)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
    "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
    "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
    "       472-476). IEEE.\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Compute empirical variance of all data (to be bounded)\n",
    "    cov = Covariances(estimator=method).fit_transform(UX[np.newaxis, ...])\n",
    "    Q = np.squeeze(cov)\n",
    "\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Intertrial correlation computation\n",
    "    data = np.concatenate((X, X), axis=1)\n",
    "\n",
    "    # Swapaxes to fit pyriemann Covariances\n",
    "    data = np.swapaxes(data, 0, 2)\n",
    "    cov = Covariances(estimator=method).fit_transform(data)\n",
    "\n",
    "    # Keep only inter-trial\n",
    "    S = cov[:, :n_chans, n_chans:] + cov[:, n_chans:, :n_chans]\n",
    "\n",
    "    # If the number of samples is too big, we compute an approximate of\n",
    "    # riemannian mean to speed up the computation\n",
    "    if n_trials < 30:\n",
    "        S = mean_covariance(S, metric='riemann')\n",
    "    else:\n",
    "        S = mean_covariance(S, metric='logeuclid')\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best\n",
    "\n",
    "\n",
    "\n",
    "def get_corr(a,b, latency=20):\n",
    "    cross_correlation = abs(np.correlate(a,b, mode='same'))\n",
    "    center_idx = len(cross_correlation) // 2\n",
    "    max_corr = cross_correlation[center_idx-latency  : center_idx+latency].max()\n",
    "    return max_corr\n",
    "\n",
    "def trca_crosscorrelation(X):\n",
    "    latency=250\n",
    "    n_samples, n_chans, n_trials = theshapeof(X)\n",
    "\n",
    "    # 1. Compute empirical covariance of all data (to be bounded)\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Concatenate all the trials to have all the data as a sequence\n",
    "    UX = np.zeros((n_chans, n_samples * n_trials))\n",
    "    for trial in range(n_trials):\n",
    "        UX[:, trial * n_samples:(trial + 1) * n_samples] = X[..., trial].T\n",
    "\n",
    "    # Mean centering\n",
    "    UX -= np.mean(UX, 1)[:, None]\n",
    "\n",
    "    # Covariance\n",
    "    # Q = UX @ UX.T\n",
    "    # Use my cross correlation\n",
    "    Q = np.zeros((UX.shape[0],UX.shape[0]))\n",
    "    for i in range(UX.shape[0]):\n",
    "        for j in range(UX.shape[0]):\n",
    "            a = UX[i]\n",
    "            b = UX[j]\n",
    "            Q[i,j] = get_corr(a,b,latency=latency)\n",
    "    # 2. Compute average empirical covariance between all pairs of trials\n",
    "    # -------------------------------------------------------------------------\n",
    "    S = np.zeros((n_chans, n_chans))\n",
    "    for i in range(n_chans):\n",
    "        for j in range(n_chans):\n",
    "            # n_samples, n_chans, n_trials \n",
    "            x_i = X[:, i, :]\n",
    "            x_j = X[:, j, :]\n",
    "            # print(f\"{x_i.shape=}\")\n",
    "            # print(f\"{x_j.shape=}\")\n",
    "            for t1 in range(n_trials):\n",
    "                for t2 in range(n_trials):\n",
    "                    if(t1 == t2): continue\n",
    "                    x_i_t1 = np.squeeze(x_i[:,t1])\n",
    "                    x_i_t1 -= x_i_t1.mean()\n",
    "\n",
    "                    x_j_t2 = np.squeeze(x_j[:,t2])\n",
    "                    x_j_t2 -= x_j_t2.mean()\n",
    "                    \n",
    "                    S[i,j] += get_corr(x_i_t1, x_j_t2, latency=latency)\n",
    "    # for trial_i in range(n_trials - 1):\n",
    "    #     x1 = np.squeeze(X[..., trial_i])\n",
    "\n",
    "    #     # Mean centering for the selected trial\n",
    "    #     x1 -= np.mean(x1, 0)\n",
    "\n",
    "    #     # Select a second trial that is different\n",
    "    #     for trial_j in range(trial_i + 1, n_trials):\n",
    "    #         x2 = np.squeeze(X[..., trial_j])\n",
    "\n",
    "    #         # Mean centering for the selected trial\n",
    "    #         x2 -= np.mean(x2, 0)\n",
    "\n",
    "    #         # Compute empirical covariance between the two selected trials and\n",
    "    #         # sum it\n",
    "    #         S = S + x1.T @ x2 + x2.T @ x1\n",
    "\n",
    "    # 3. Compute eigenvalues and vectors\n",
    "    # -------------------------------------------------------------------------\n",
    "    lambdas, W = linalg.eig(S, Q, left=True, right=False)\n",
    "\n",
    "    # Select the eigenvector corresponding to the biggest eigenvalue\n",
    "    W_best = W[:, np.argmax(lambdas)]\n",
    "\n",
    "    return W_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRCA:\n",
    "    \"\"\"Task-Related Component Analysis (TRCA).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sfreq : float\n",
    "        Sampling rate.\n",
    "    filterbank : list[[2-tuple, 2-tuple]]\n",
    "        Filterbank frequencies. Each list element is itself a list of passband\n",
    "        `Wp` and stopband `Ws` edges frequencies `[Wp, Ws]`. For example, this\n",
    "        creates 3 bands, starting at 6, 14, and 22 hz respectively::\n",
    "\n",
    "            [[(6, 90), (4, 100)],\n",
    "             [(14, 90), (10, 100)],\n",
    "             [(22, 90), (16, 100)]]\n",
    "\n",
    "        See :func:`scipy.signal.cheb1ord()` for more information on how to\n",
    "        specify the `Wp` and `Ws`.\n",
    "    ensemble : bool\n",
    "        If True, perform the ensemble TRCA analysis (default=False).\n",
    "    method : str in {'original'| 'riemann'}\n",
    "        Use original implementation from [1]_ or a variation that uses\n",
    "        regularization and the geodesic mean [2]_.\n",
    "    regularization : str in {'schaefer' | 'lwf' | 'oas' | 'scm'}\n",
    "        Regularization estimator used for covariance estimation with the\n",
    "        `riemann` method. Consider 'schaefer', 'lwf', 'oas'. 'scm' does not add\n",
    "        regularization and is almost equivalent to the original implementation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    traindata : array, shape=(n_bands, n_chans, n_trials)\n",
    "        Reference (training) data decomposed into sub-band components by the\n",
    "        filter bank analysis.\n",
    "    y_train : array, shape=(n_trials)\n",
    "        Labels associated with the train data.\n",
    "    coef_ : array, shape=(n_chans, n_chans)\n",
    "        Weight coefficients for electrodes which can be used as a spatial\n",
    "        filter.\n",
    "    classes : list\n",
    "        Classes.\n",
    "    n_bands : int\n",
    "        Number of sub-bands.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] M. Nakanishi, Y. Wang, X. Chen, Y. -T. Wang, X. Gao, and T.-P. Jung,\n",
    "       \"Enhancing detection of SSVEPs for a high-speed brain speller using\n",
    "       task-related component analysis\", IEEE Trans. Biomed. Eng,\n",
    "       65(1):104-112, 2018.\n",
    "    .. [2] Barachant, A., Bonnet, S., Congedo, M., & Jutten, C. (2010,\n",
    "       October). Common spatial pattern revisited by Riemannian geometry. In\n",
    "       2010 IEEE International Workshop on Multimedia Signal Processing (pp.\n",
    "       472-476). IEEE.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sfreq, filterbank, ensemble=False, method='original',\n",
    "                 estimator='scm'):\n",
    "        self.sfreq = sfreq\n",
    "        self.ensemble = ensemble\n",
    "        self.filterbank = filterbank\n",
    "        self.n_bands = len(self.filterbank)\n",
    "        self.coef_ = None\n",
    "        self.method = method\n",
    "        if estimator == 'schaefer':\n",
    "            self.estimator = schaefer_strimmer_cov\n",
    "        else:\n",
    "            self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Training stage of the TRCA-based SSVEP detection.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array, shape=(n_samples, n_chans[, n_trials])\n",
    "            Training EEG data.\n",
    "        y : array, shape=(trials,)\n",
    "            True label corresponding to each trial of the data array.\n",
    "\n",
    "        \"\"\"\n",
    "        n_samples, n_chans, _ = theshapeof(X)\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        trains = np.zeros((len(classes), self.n_bands, n_samples, n_chans))\n",
    "\n",
    "        W = np.zeros((self.n_bands, len(classes), n_chans))\n",
    "\n",
    "        for class_i in classes:\n",
    "            # Select data with a specific label\n",
    "            eeg_tmp = X[..., y == class_i]\n",
    "            for fb_i in range(self.n_bands):\n",
    "                # Filter the signal with fb_i\n",
    "                eeg_tmp = bandpass(eeg_tmp, self.sfreq,\n",
    "                                   Wp=self.filterbank[fb_i][0],\n",
    "                                   Ws=self.filterbank[fb_i][1])\n",
    "                if (eeg_tmp.ndim == 3):\n",
    "                    # Compute mean of the signal across trials\n",
    "                    trains[class_i, fb_i] = np.mean(eeg_tmp, -1)\n",
    "                else:\n",
    "                    trains[class_i, fb_i] = eeg_tmp\n",
    "                # Find the spatial filter for the corresponding filtered signal\n",
    "                # and label\n",
    "                if self.method == 'original':\n",
    "                    w_best = _trca(eeg_tmp)\n",
    "                elif self.method == 'riemann':\n",
    "                    w_best = trca_regul(eeg_tmp, self.estimator)\n",
    "                elif self.method == 'crosscorrelation':\n",
    "                    w_best = trca_crosscorrelation(eeg_tmp)\n",
    "                else:\n",
    "                    raise ValueError('Invalid `method` option.')\n",
    "\n",
    "                W[fb_i, class_i, :] = w_best  # Store the spatial filter\n",
    "\n",
    "        self.trains = trains\n",
    "        self.coef_ = W\n",
    "        self.classes = classes\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Test phase of the TRCA-based SSVEP detection.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array, shape=(n_samples, n_chans[, n_trials])\n",
    "            Test data.\n",
    "        model: dict\n",
    "            Fitted model to be used in testing phase.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pred: np.array, shape (trials)\n",
    "            The target estimated by the method.\n",
    "\n",
    "        \"\"\"\n",
    "        if self.coef_ is None:\n",
    "            raise RuntimeError('TRCA is not fitted')\n",
    "\n",
    "        # Alpha coefficients for the fusion of filterbank analysis\n",
    "        fb_coefs = [(x + 1)**(-1.25) + 0.25 for x in range(self.n_bands)]\n",
    "        _, _, n_trials = theshapeof(X)\n",
    "\n",
    "        r = np.zeros((self.n_bands, len(self.classes)))\n",
    "        pred = np.zeros((n_trials), 'int')  # To store predictions\n",
    "\n",
    "        for trial in range(n_trials):\n",
    "            test_tmp = X[..., trial]  # pick a trial to be analysed\n",
    "            for fb_i in range(self.n_bands):\n",
    "\n",
    "                # filterbank on testdata\n",
    "                testdata = bandpass(test_tmp, self.sfreq,\n",
    "                                    Wp=self.filterbank[fb_i][0],\n",
    "                                    Ws=self.filterbank[fb_i][1])\n",
    "\n",
    "                for class_i in self.classes:\n",
    "                    # Retrieve reference signal for class i\n",
    "                    # (shape: n_chans, n_samples)\n",
    "                    traindata = np.squeeze(self.trains[class_i, fb_i])\n",
    "                    if self.ensemble:\n",
    "                        # shape = (n_chans, n_classes)\n",
    "                        w = np.squeeze(self.coef_[fb_i]).T\n",
    "                    else:\n",
    "                        # shape = (n_chans)\n",
    "                        w = np.squeeze(self.coef_[fb_i, class_i])\n",
    "\n",
    "                    # Compute 2D correlation of spatially filtered test data\n",
    "                    # with ref\n",
    "                    r_tmp = np.corrcoef((testdata @ w).flatten(),\n",
    "                                        (traindata @ w).flatten())\n",
    "                    r[fb_i, class_i] = r_tmp[0, 1]\n",
    "\n",
    "            rho = np.dot(fb_coefs, r)  # fusion for the filterbank analysis\n",
    "\n",
    "            tau = np.argmax(rho)  # retrieving index of the max\n",
    "            pred[trial] = int(tau)\n",
    "\n",
    "        return pred\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sunsun\\.virtualenvs\\HybridSpeller-q8UBACmb\\lib\\site-packages\\scipy\\signal\\_filter_design.py:3975: RuntimeWarning: divide by zero encountered in divide\n",
      "  nat = ((stopb ** 2 - passb[0] * passb[1]) /\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TRCA at 0x21a93103820>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TRCA(sfreq, filterbank, is_ensemble, method='original')\n",
    "model.fit(np.swapaxes(X,0,2),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
      "Fold 0:\n",
      "  Train:  [11 10 15  3  5  9  4 14  6  1  0  8 12  5 14  0 15  7 10  9  8 13 12  2\n",
      " 11  4  3  6  1  5 14  0 15  7 10  9  8 13 12  2 11  4  3  6  1 10  1 14\n",
      " 11  0  9  2  3  7  5 12 15  4  6  8 13 10  1 14 11  0  9  2  3  7  5 12\n",
      " 15  4  6  8 13  0  4 11 12  3 10  2  1  6 15  7  5  8 14 13  9  0  4 11\n",
      " 12  3 10  2  1  6 15  7  5  8 14 13  9  4 13  7  3 10  2  8 12 14  5  1\n",
      " 15  6  0 11  9  4 13  7  3 10  2  8 12 14  5  1 15  6  0 11  9  1 14  5\n",
      "  2  4  3 11  8 10  7 13  6  0 15  9 12  1 14  5  2  4  3 11  8 10  7 13\n",
      "  6  0 15  9 12  6  5  1 13 15  9  7 11  2 12  8  4 14  3  0 10  6  5  1\n",
      " 13 15  9  7 11  2 12  8  4]\n",
      "  Test:  [ 2 10  5  1  8  0 11 13  9  3 12 14 15  6  7  4  2 10  5  1  8  0 11 13\n",
      "  9  3 12 14 15  6  7  4 11 10 15 13  3  2  7  5  9  4 14  6  1  0  8 12\n",
      " 13  2  7]\n",
      "(201, 8, 750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sunsun\\.virtualenvs\\HybridSpeller-q8UBACmb\\lib\\site-packages\\scipy\\signal\\_filter_design.py:3975: RuntimeWarning: divide by zero encountered in divide\n",
      "  nat = ((stopb ** 2 - passb[0] * passb[1]) /\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 10  5  1  8  0 11 13  9  3 12 14 15  6  7  4  2 10  5  1  8  0 11 13\n",
      "  9  3 12 14 15  6  7  4 11 10 15 13  3  2  7  5  9  4 14  6  1  0  8 12\n",
      " 13  2  7]\n",
      "[ 3 10  6  3  3  6 11  9 12 10  1 13  9 11 14 12  3 11 11  9  9  7 11 13\n",
      "  4 15 12 12  4  2 15  5  9 13 15 13  3 13  2  5  9  1 14  3  3  6  3 13\n",
      " 14  2 10]\n",
      "0.23529411764705882\n",
      "Fold 1:\n",
      "  Train:  [ 2 10  5  1  8  0 11 13  9  3 12 14 15  6  7  4  2 10  5  1  8  0 11 13\n",
      "  9  3 12 14 15  6  7  4 11 10 15 13  3  2  7  5  9  4 14  6  1  0  8 12\n",
      " 13  2  7 10  1 14 11  0  3 12 15  6  8 10  1 14 11  0  9  2  3  7  5 12\n",
      " 15  4  6  8 13  0  4 11 12  3 10  2  1  6 15  7  5  8 14 13  9  0  4 11\n",
      " 12  3 10  2  1  6 15  7  5  8 14 13  9  4 13  7  3 10  2  8 12 14  5  1\n",
      " 15  6  0 11  9  4 13  7  3 10  2  8 12 14  5  1 15  6  0 11  9  1 14  5\n",
      "  2  4  3 11  8 10  7 13  6  0 15  9 12  1 14  5  2  4  3 11  8 10  7 13\n",
      "  6  0 15  9 12  6  5  1 13 15  9  7 11  2 12  8  4 14  3  0 10  6  5  1\n",
      " 13 15  9  7 11  2 12  8  4]\n",
      "  Test:  [11 10 15  3  5  9  4 14  6  1  0  8 12  5 14  0 15  7 10  9  8 13 12  2\n",
      " 11  4  3  6  1  5 14  0 15  7 10  9  8 13 12  2 11  4  3  6  1  9  2  7\n",
      "  5  4 13]\n",
      "(201, 8, 750)\n",
      "[11 10 15  3  5  9  4 14  6  1  0  8 12  5 14  0 15  7 10  9  8 13 12  2\n",
      " 11  4  3  6  1  5 14  0 15  7 10  9  8 13 12  2 11  4  3  6  1  9  2  7\n",
      "  5  4 13]\n",
      "[ 3  2 11  6  5 11 11  3 15  8  5 14 13  2 15  6 15 15  3  9  8  3 12 10\n",
      "  7  7 10 10  3 10 14  4 11  4 14  3  8 13 12 11  1  3 11  3  8  8  9 11\n",
      "  4  3 13]\n",
      "0.19607843137254902\n",
      "Fold 2:\n",
      "  Train:  [ 2 10  5  1  8  0 11 13  9  3 12 14 15  6  7  4  2 10  5  1  8  0 11 13\n",
      "  9  3 12 14 15  6  7  4 11 10 15 13  3  2  7  5  9  4 14  6  1  0  8 12\n",
      " 11 10 15 13  3  2  7  5  9  4 14  6  1  0  8 12  5 14  0 15  7 10  9  8\n",
      " 13 12  2 11  4  3  6  1  5 14  0 15  7 10  9  8 13 12  2 11  4  3  6  1\n",
      "  9  2  7  5  4 13  0 11  3 10  6 15  8 14  4 13  7  3 10  2  8 12 14  5\n",
      "  1 15  6  0 11  9  4 13  7  3 10  2  8 12 14  5  1 15  6  0 11  9  1 14\n",
      "  5  2  4  3 11  8 10  7 13  6  0 15  9 12  1 14  5  2  4  3 11  8 10  7\n",
      " 13  6  0 15  9 12  6  5  1 13 15  9  7 11  2 12  8  4 14  3  0 10  6  5\n",
      "  1 13 15  9  7 11  2 12  8  4]\n",
      "  Test:  [10  1 14 11  0  3 12 15  6  8 10  1 14 11  0  9  2  3  7  5 12 15  4  6\n",
      "  8 13  0  4 11 12  3 10  2  1  6 15  7  5  8 14 13  9  4 12  2  1  7  5\n",
      " 13  9]\n",
      "(202, 8, 750)\n",
      "[10  1 14 11  0  3 12 15  6  8 10  1 14 11  0  9  2  3  7  5 12 15  4  6\n",
      "  8 13  0  4 11 12  3 10  2  1  6 15  7  5  8 14 13  9  4 12  2  1  7  5\n",
      " 13  9]\n",
      "[ 3 13 13 11 11  9  0 14  0  2 10 14 13  2  5 12  6  1 13  8 14  7 11  5\n",
      "  4  3  8  4 11 11 11 13 12  1 15  8 10  1 13 15  0  9  6  4 14  0  5 10\n",
      " 13  8]\n",
      "0.14\n",
      "Fold 3:\n",
      "  Train:  [ 2 10  5  1  8  0 11 13  9  3 12 14 15  6  7  4  2 10  5  1  8  0 11 13\n",
      "  9  3 12 14 15  6  7  4 11 10 15 13  3  2  7  5  9  4 14  6  1  0  8 12\n",
      " 11 10 15 13  3  2  7  5  9  4 14  6  1  0  8 12  5 14  0 15  7 10  9  8\n",
      " 13 12  2 11  4  3  6  1  5 14  0 15  7 10  9  8 13 12  2 11  4  3  6  1\n",
      " 10  1 14 11  0  9  2  3  7  5 12 15  4  6  8 13 10  1 14 11  0  9  2  3\n",
      "  7  5 12 15  4  6  8 13  0  4 11 12  3 10  2  1  6 15  7  5  8 14 13  9\n",
      "  4 12  2  1  7  5 13  9 14  3 11 10  6  0  1 14  5  2  4  3 11  8 10  7\n",
      " 13  6  0 15  9 12  6  5  1 13 15  9  7 11  2 12  8  4 14  3  0 10  6  5\n",
      "  1 13 15  9  7 11  2 12  8  4]\n",
      "  Test:  [ 0 11  3 10  6 15  8 14  4 13  7  3 10  2  8 12 14  5  1 15  6  0 11  9\n",
      "  4 13  7  3 10  2  8 12 14  5  1 15  6  0 11  9  1  5  2  4  8  7 13 15\n",
      "  9 12]\n",
      "(202, 8, 750)\n",
      "[ 0 11  3 10  6 15  8 14  4 13  7  3 10  2  8 12 14  5  1 15  6  0 11  9\n",
      "  4 13  7  3 10  2  8 12 14  5  1 15  6  0 11  9  1  5  2  4  8  7 13 15\n",
      "  9 12]\n",
      "[ 9 10  3 10  8  8 10  6 15 12 11  1  1  2  1 12 15  1  4  0 15  2 10 13\n",
      "  4 15  9 10  4 11  0 10 14  1  0 12  9  0 12  7  1 10  1  4  4  7  7  6\n",
      " 13  2]\n",
      "0.2\n",
      "Fold 4:\n",
      "  Train:  [ 2 10  5  1  8  0 11 13  9  3 12 14 15  6  7  4  2 10  5  1  8  0 11 13\n",
      "  9  3 12 14 15  6  7  4 11 10 15 13  3  2  7  5  9  4 14  6  1  0  8 12\n",
      " 11 10 15 13  3  2  7  5  9  4 14  6  1  0  8 12  5 14  0 15  7 10  9  8\n",
      " 13 12  2 11  4  3  6  1  5 14  0 15  7 10  9  8 13 12  2 11  4  3  6  1\n",
      " 10  1 14 11  0  9  2  3  7  5 12 15  4  6  8 13 10  1 14 11  0  9  2  3\n",
      "  7  5 12 15  4  6  8 13  0  4 11 12  3 10  2  1  6 15  7  5  8 14 13  9\n",
      "  0  4 11 12  3 10  2  1  6 15  7  5  8 14 13  9  4 13  7  3 10  2  8 12\n",
      " 14  5  1 15  6  0 11  9  4 13  7  3 10  2  8 12 14  5  1 15  6  0 11  9\n",
      "  1  5  2  4  8  7 13 15  9 12]\n",
      "  Test:  [14  3 11 10  6  0  1 14  5  2  4  3 11  8 10  7 13  6  0 15  9 12  6  5\n",
      "  1 13 15  9  7 11  2 12  8  4 14  3  0 10  6  5  1 13 15  9  7 11  2 12\n",
      "  8  4]\n",
      "(202, 8, 750)\n",
      "[14  3 11 10  6  0  1 14  5  2  4  3 11  8 10  7 13  6  0 15  9 12  6  5\n",
      "  1 13 15  9  7 11  2 12  8  4 14  3  0 10  6  5  1 13 15  9  7 11  2 12\n",
      "  8  4]\n",
      "[ 3  3 11  7 14 11  1  2  3  2  1 13 10  8 11 11  8  0 11  7 11  9  2  5\n",
      "  3  5 11  4  8  9  7 14  9  4 14 10  1  3 11 11  1 11 15 15  9  8 11 14\n",
      "  6  4]\n",
      "0.22\n",
      "Average accuracy ==> 0.19827450980392158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)\n",
    "accs = []\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: \", y[train_index])\n",
    "    print(f\"  Test: \", y[test_index])\n",
    "    print(X[train_index].shape)\n",
    "    X_train = np.swapaxes(X[train_index], 0,2)\n",
    "    X_test = np.swapaxes(X[test_index],0,2)\n",
    "    model = TRCA(sfreq, filterbank, is_ensemble, method='original')\n",
    "    model.fit(X_train, y[train_index])\n",
    "    preds = model.predict(X_test)\n",
    "    acc = np.mean(preds == y[test_index])\n",
    "    accs.append(acc)\n",
    "    print(y[test_index])\n",
    "    print(preds)\n",
    "    print(acc)\n",
    "print(\"Average accuracy ==>\", np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'nakanishi_TRCA_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HybridSpeller-q8UBACmb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
